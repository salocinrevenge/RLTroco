{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Projeto 1\n",
        "\n",
        "Este trabalho compara a eficiÃªncia e eficÃ¡cia de mÃºltiplos algoritmos de Aprendizado por ReforÃ§o (RL), sem eles MonteCarlo, Sarsa(Lambda) e Q_learning, em diferentes cenÃ¡rios e variando seus parÃ¢metros quando necessÃ¡rio. O ambiente/problema que foi usado como teste sÃ£o labirintos, onde os algoritmos precisam encontrar uma politica Ã³tima para que o agente consiga chegar atÃ© o final do labirinto.\n",
        "\n",
        "### Ambiente\n",
        "Como dito anteriormente, os ambientes sÃ£o labirintos. Eles sÃ£o descritos por meio de arquivos .txt, onde sÃ£o apontados as paredes, caminhos, estados terminais, formato e suas recompensas. Os arquivos tÃªm essa cara:\n",
        "```\n",
        "4 4\n",
        ". path -1\n",
        "@ agent -1\n",
        "$ goal 100\n",
        "# wall -1000\n",
        "######\n",
        "#...$#\n",
        "#@...#\n",
        "######\n",
        "```\n",
        "\n",
        "Aqui Ã© descrito um labirinto de tamanho 4x4, onde os caminhos sÃ£o '.' e possuem recompensa de -1. Por sua o estado terminal, ou objetivo, Ã© representado por '$' e possui recompensa de 100. Por fim, apÃ³s a descriÃ§Ã£o dos simbolos, hÃ¡ a descriÃ§Ã£o do prÃ³prio formato do labirinto.\n",
        "\n",
        "Diferentes formatos de labirintos foram adotados para o trabalho, sendo alguns bem aplos, outros com diversos caminhos, e outros extremamente estreitos. As recompensas tambÃ©m foram alteradas para avaliar seu impacto, jÃ¡ que a escolha de uma funÃ§Ã£o de recompensa boa tambÃ©m faz parte do processo quando se trabalha com RL.\n",
        "\n",
        "### CÃ³digo\n",
        "As primeiras cÃ©lulas desse notebook contÃ©m o cÃ³digo usado para implementaÃ§Ã£o e obtenÃ§Ã£o dos resultados. PorÃ©m para facilitar, foram geradas imagens com os resultados obtidos, e a anÃ¡lise foi feita em cima delas. O cÃ³digo fica a disposiÃ§Ã£o para quem quiser rodar novamente, mudar valores, testar outras configuraÃ§Ãµes de labirinto.\n",
        "\n",
        "### MÃ©tricas\n",
        "Para comparaÃ§Ã£o dos algoritmos entre si, foram extraÃ­das as recompensas mÃ©dias e o tamanho do caminho percorrido a partir de um mesmo ponto do mapa. Com isso Ã© possÃ­vel analisar o quÃ£o eficiente foi o caminho encontrado pelo algoritmo, caso encontrado, e se ele conseguiu convergir. HÃ¡ tambÃ©m a analise de desempenho e custo computacional, em mÃ©dia quantos episÃ³dios foram necessÃ¡rios para que o algoritmo converja? Quanto tempo de treinamento um algoritmo precisou para isso? HÃ¡ tambÃ©m as analises individuais. Quantos hiperparametros sÃ£o necessÃ¡rios para ajustar o algoritmo, e o quÃ£o dificil Ã© encontrar um valor Ã³timo?  \n",
        "\n",
        "AlÃ©m disso, um mapa de calor gerado a partir da funÃ§Ã£o valor serÃ¡ usado para ilustrar o quÃ£o bom Ã© estar em cada estado, ou seja, em cada posiÃ§Ã£o do labirinto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lftFAb-BqMew"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from itertools import product\n",
        "import random\n",
        "from threading import Thread\n",
        "import time\n",
        "from argparse import ArgumentParser\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "OwSgimmVxFIw"
      },
      "outputs": [],
      "source": [
        "class Renderer():\n",
        "    def __init__(self, chief, content, title=None, dimensions=(800, 800)):\n",
        "        self.chief = chief\n",
        "        self.content = content\n",
        "        self.contents = [content] # para trocar entre janelas\n",
        "        self.iConteudoAtual = 0 # para marcar qual o atual dentre os varios\n",
        "        self.title = title\n",
        "        self.dimensions = dimensions\n",
        "        self.running = True\n",
        "        if not self.title:\n",
        "            self.title = type(chief).__name__   # title Ã© o nome da classe\n",
        "        \n",
        "        self.load_sprites()\n",
        "\n",
        "    def add_content(self,content):\n",
        "        self.contents.append(content)\n",
        "\n",
        "    def load_sprites(self):\n",
        "        self.sprites = dict()\n",
        "        self.sprites[\"path\"] = 'â¬›'\n",
        "        self.sprites[\"wall\"] = 'ğŸ§±'\n",
        "        self.sprites[\"goal\"] = 'âš½'\n",
        "        self.sprites[\"agent\"] = 'ğŸ‘¾' \n",
        "        self.sprites[\"right\"] = 'â¡ï¸'\n",
        "        self.sprites[\"up\"] = 'â¬†ï¸'\n",
        "        self.sprites[\"left\"] = 'â¬…ï¸' \n",
        "        self.sprites[\"down\"] = 'â¬‡ï¸'\n",
        "\n",
        "\n",
        "    def show(self):\n",
        "        for i in range(len(self.content)):\n",
        "            for j in range(len(self.content[0])):\n",
        "                cell = self.content[i][j]\n",
        "                # se o content de cell estiver no dicionario de sprites\n",
        "                if cell in self.sprites:\n",
        "                    obj = cell\n",
        "                else:\n",
        "                    obj = self.chief.symbols[cell]\n",
        "                print(self.sprites.get(obj,'âŒ'),end='')\n",
        "            print('')\n",
        "\n",
        "    def create_heatmap(data, cmap='viridis', title='Heatmap'):\n",
        "        \"\"\"\n",
        "        Create a heatmap from a list of lists of floats.\n",
        "\n",
        "        Parameters:\n",
        "        - data: List of lists of floats representing the heatmap data.\n",
        "        - cmap: Colormap for the heatmap (default is 'viridis').\n",
        "        - title: Title for the heatmap (default is 'Heatmap').\n",
        "        \"\"\"\n",
        "        data = np.array(data, dtype=float)\n",
        "\n",
        "        # Create a figure and axis\n",
        "        fig, ax = plt.subplots()\n",
        "\n",
        "        # Display the heatmap using imshow\n",
        "        im = ax.imshow(data, cmap=cmap)\n",
        "\n",
        "        # Add a colorbar to the right of the heatmap\n",
        "        cbar = ax.figure.colorbar(im, ax=ax)\n",
        "\n",
        "        # Set the title\n",
        "        ax.set_title(title)\n",
        "\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "\n",
        "    def show_path(self, path):\n",
        "        for i in range(len(self.content)):\n",
        "            for j in range(len(self.content[0])):\n",
        "                cell = self.content[i][j]\n",
        "                if((i,j) in path.keys()):\n",
        "                    cell = path[(i,j)]\n",
        "                # se o content de cell estiver no dicionario de sprites\n",
        "                if cell in self.sprites:\n",
        "                    obj = cell\n",
        "                else:\n",
        "                    obj = self.chief.symbols[cell]\n",
        "                print(self.sprites.get(obj,'âŒ'),end='')\n",
        "            print('')\n",
        "\n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Agent():\n",
        "    actions = ['up', 'down', 'left', 'right']\n",
        "    def __init__(self, x, y, environment, gamma = 0.9, display=True):\n",
        "        self.environment = environment\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.gamma = gamma\n",
        "        self.display = display\n",
        "\n",
        "    def action_idx(self, action: str):\n",
        "        return self.actions.index(action)\n",
        "\n",
        "\n",
        "    def startQ(self, shape, start_value = float(\"-inf\")):\n",
        "        \"\"\"\n",
        "        livroQ Ã© uma lista de listas de dicionarios,\n",
        "        ele armazena \n",
        "        \n",
        "        \"\"\"\n",
        "        self.book_Q: list[list[dict]] = []\n",
        "        for i in range(shape[0]):\n",
        "            self.book_Q.append([])\n",
        "            for _ in range(shape[1]):\n",
        "                self.book_Q[i].append(dict())\n",
        "                for action in self.actions:\n",
        "                    self.book_Q[i][-1][action] = start_value\n",
        "\n",
        "    def startV(self, shape):\n",
        "        \"\"\"\n",
        "        livroV Ã© uma lista de listas de dicionarios,\n",
        "        ele armazena \n",
        "        \n",
        "        \"\"\" \n",
        "        self.book_V: list[list] = []\n",
        "        for i in range(shape[0]):\n",
        "            self.book_V.append([])\n",
        "            for _ in range(shape[1]):\n",
        "                \n",
        "                self.book_V[i].append(float(\"-inf\"))\n",
        "    \n",
        "    def startPolicy(self, shape, randomPolicy):\n",
        "        \"\"\"\n",
        "        A policy Ã© uma matriz de caracteres que guarda a action principal\n",
        "        a ser tomada ate o momento\n",
        "        \n",
        "        \"\"\"\n",
        "        self.policy: list[list[str]] = []\n",
        "        for i in range(shape[0]):\n",
        "            self.policy.append([])\n",
        "            for j in range(shape[1]):\n",
        "                if self.environment.symbols[self.environment.original_map[i][j]] == \"wall\":\n",
        "                    self.policy[i].append(\"wall\")\n",
        "                    continue\n",
        "                if randomPolicy:\n",
        "                    self.policy[i].append(random.choice(self.actions))\n",
        "                else:\n",
        "                    self.policy[i].append(self.actions[0])\n",
        "        if self.display:\n",
        "            self.render = Renderer(self, self.policy, \"Agente\")\n",
        "\n",
        "    def startReturns(self, shape):\n",
        "        \"\"\"\n",
        "        returns Ã© uma colecao de pares state action guardando um\n",
        "        dicionario para armazenar o valor maximo de rewards obtidos,\n",
        "        o numero de vezes que o par state action foi visitado e o ultimo\n",
        "        episodio em que o par state action foi visitado\n",
        "        \"\"\"\n",
        "        self.returns: list[list[dict]] = []\n",
        "        for i in range(shape[0]):\n",
        "            self.returns.append([])\n",
        "            for j in range(shape[1]):\n",
        "                self.returns[i].append(dict())\n",
        "                for action in self.actions:\n",
        "                    self.returns[i][j][action] = {\"value\": 0, \"count\": 0, \"lastEpisode\": 0}\n",
        "\n",
        "    def setEnvironment(self, environment):\n",
        "        self.environment = environment\n",
        "    \n",
        "    def setPos(self, position):\n",
        "        self.x = position[1]\n",
        "        self.y = position[0]\n",
        "\n",
        "    def move(self, action):\n",
        "        return self.environment.move(self, action)\n",
        "    \n",
        "    def get_action(self):\n",
        "        return self.policy[self.y][self.x]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlGKK60NqTV4",
        "outputId": "d6167f45-bc5f-49b6-8732-de679f17aeec"
      },
      "outputs": [],
      "source": [
        "class LearningStrategy():\n",
        "    def train(self, episodes):\n",
        "        pass\n",
        "\n",
        "    def setup(self, environment, agent):\n",
        "        self.environment = environment\n",
        "        self.agent = agent\n",
        "\n",
        "class MonteCarlo(LearningStrategy):\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "\n",
        "    \n",
        "    def train(self, episodes, randomPolicy = True, exploration_chance = 0):\n",
        "        # Initialize\n",
        "        shape = self.environment.get_size()\n",
        "        self.agent.startPolicy(shape, randomPolicy)\n",
        "        self.agent.startReturns(shape)\n",
        "        self.agent.startQ(shape)\n",
        "        self.agent.startV(shape)\n",
        "\n",
        "        for ep in range(episodes):\n",
        "            if ep % (episodes//10) == 0:\n",
        "                print(f\"{ep=}\")\n",
        "                path = self.path_from((1,1))\n",
        "                print('Tamanho do episÃ³dio:', len(path))\n",
        "                print('Recompensa', sum([i[2] for i in path]))\n",
        "                path_dict = {}\n",
        "                for s,a,r in path:\n",
        "                    path_dict[s] = a\n",
        "                self.environment.render.show_path(path_dict)\n",
        "            # escolhe posicao aleatoria valida para o agente\n",
        "            while True:\n",
        "                state = (random.randrange(0, shape[0]), random.randrange(0, shape[1]))\n",
        "                if self.environment.original_map[state[0]][state[1]] in {self.environment.default_symbols[\"path\"], self.environment.default_symbols[\"goal\"]}:\n",
        "                    break\n",
        "            # escolhe uma action diferente da dita pela politica atual\n",
        "            for _ in range(len(self.agent.actions)*2):    # limite maximo de tentativas\n",
        "                action = random.choice(self.agent.actions)\n",
        "                if action != self.agent.policy[state[0]][state[1]]:\n",
        "                    # se a action nao te leva para uma parede\n",
        "                    if self.environment.util(state, action): \n",
        "                        break\n",
        "            else:\n",
        "                action = self.agent.policy[state[0]][state[1]]\n",
        "            self.episode(state, action, max_steps= shape[1]*shape[0], exploration_chance = exploration_chance)\n",
        "            g = 0\n",
        "            for t in range(len(self.agent.recalls)-1, -1, -1): \n",
        "                memory = self.agent.recalls[t]  # memory = (state, action, reforco)\n",
        "                g = self.agent.gamma*g + memory[2]\n",
        "                # verifica se o par state action ja foi inserido em returns\n",
        "                if self.agent.returns[memory[0][0]][memory[0][1]][memory[1]][\"lastEpisode\"] != ep:\n",
        "                    self.agent.returns[memory[0][0]][memory[0][1]][memory[1]][\"lastEpisode\"] = ep\n",
        "                    self.agent.returns[memory[0][0]][memory[0][1]][memory[1]][\"value\"] += g\n",
        "                    self.agent.returns[memory[0][0]][memory[0][1]][memory[1]][\"count\"] += 1\n",
        "                    media = self.agent.returns[memory[0][0]][memory[0][1]][memory[1]][\"value\"]/self.agent.returns[memory[0][0]][memory[0][1]][memory[1]][\"count\"]\n",
        "                    self.agent.book_Q[memory[0][0]][memory[0][1]][memory[1]] = media\n",
        "                    self.agent.book_V[memory[0][0]][memory[0][1]] = media\n",
        "                    self.agent.policy[memory[0][0]][memory[0][1]] = max(self.agent.actions, key = lambda action: self.agent.book_Q[memory[0][0]][memory[0][1]][action])    # recebe a action que maximiza o valor de Q\n",
        "\n",
        "    def episode(self, state, action, max_steps, exploration_chance=0):\n",
        "        step_count = 0\n",
        "        self.agent.recalls = []\n",
        "        self.environment.setAgentPos(state[0], state[1])\n",
        "\n",
        "        while (not self.environment.in_terminal_state()) and (step_count < max_steps):  # enquanto nao estiver em um state terminal\n",
        "            step_count +=1  # incrementa o numero de passos\n",
        "            lastPos = (self.agent.y, self.agent.x)\n",
        "            reward = self.environment.move(self.agent,action) # realiza a action e recebe a recompensa\n",
        "            self.agent.recalls.append((lastPos, action, reward)) # guarda o passo\n",
        "            if random.random() < exploration_chance:\n",
        "                for _ in range(len(self.agent.actions)*2):    # limite maximo de tentativas\n",
        "                    action = random.choice(self.agent.actions)\n",
        "                    # se a action nao te leva para uma parede\n",
        "                    if self.environment.util(state, action): break\n",
        "            else:\n",
        "                action = self.agent.get_action() # escolhe uma action de acordo com a politica\n",
        "\n",
        "    def path_from(self, starting_point):\n",
        "        shape = self.environment.get_size()\n",
        "        max_steps = shape[0] * shape[1]\n",
        "        step_count = 0\n",
        "        state = starting_point\n",
        "        self.environment.setAgentPos(state[0], state[1])\n",
        "        tuples = []\n",
        "        while (not self.environment.in_terminal_state()) and (step_count < max_steps):\n",
        "            action =  self.agent.policy[state[0]][state[1]]\n",
        "            R = self.environment.move(self.agent, action)\n",
        "            tuples.append((state,action,R))\n",
        "            state = (self.agent.y, self.agent.x)\n",
        "            step_count+=1\n",
        "        return tuples\n",
        "\n",
        "\n",
        "class SARSA(LearningStrategy):\n",
        "\n",
        "    def __init__(self, lam):\n",
        "        super().__init__()\n",
        "        self.lam = lam\n",
        "        self.episode_R = []\n",
        "        self.episode_length = []\n",
        "\n",
        "    def get_greedy_action(self,state,Q):\n",
        "        return max(self.agent.actions, key = lambda action: Q[state[0], state[1], self.agent.action_idx(action)])\n",
        "    \n",
        "    def get_epsilon_greedy(self, exploration_chance, state, Q):\n",
        "        if random.random() < exploration_chance:\n",
        "            return random.choice(self.agent.actions)\n",
        "        else:\n",
        "            return max(self.agent.actions, key = lambda action: Q[state[0], state[1], self.agent.action_idx(action)])\n",
        "                \n",
        "    def train(self, episodes, random_policy=True, exploration_chance=0.3, alpha=0.001):\n",
        "        shape = self.environment.get_size()\n",
        "        ec = exploration_chance\n",
        "        num_states = shape[0]*shape[1]\n",
        "        linear_decay = exploration_chance/episodes\n",
        "        Q = np.zeros((shape[0],shape[1], len(self.agent.actions)))\n",
        "        E = dict()\n",
        "        for ep in range(episodes):\n",
        "            episode_R = []\n",
        "            if ep % (episodes//10) == 0: \n",
        "                print(f\"{ep=}\")\n",
        "                path = self.path_from((1,1),Q)\n",
        "                print('Tamanho do episÃ³dio:', len(path))\n",
        "                print('Recompensa', sum([i[2] for i in path]))\n",
        "                path_dict = {}\n",
        "                for s,a,r in path:\n",
        "                    path_dict[s] = a\n",
        "                self.environment.render.show_path(path_dict)\n",
        "\n",
        "            E = dict()         \n",
        "            \n",
        "            # escolhe posicao aleatoria valida para o agente\n",
        "            while True:\n",
        "                S = (random.randrange(0, shape[0]), random.randrange(0, shape[1]))\n",
        "                if self.environment.original_map[S[0]][S[1]] in {self.environment.default_symbols[\"path\"], self.environment.default_symbols[\"goal\"]}:\n",
        "                    break\n",
        "            self.environment.setAgentPos(S[0], S[1])\n",
        "\n",
        "            #A = random.choice(self.agent.actions)\n",
        "            A = self.get_epsilon_greedy(ec,S,Q)\n",
        "            A_idx = self.agent.action_idx(A)\n",
        "\n",
        "            step_count = 0\n",
        "            while (not self.environment.in_terminal_state()) and (step_count < num_states):\n",
        "\n",
        "                R = self.environment.move(self.agent, A)\n",
        "                episode_R.append(R)\n",
        "                S_prime = (self.agent.y, self.agent.x)\n",
        "                A_prime = self.get_epsilon_greedy(ec, S_prime, Q)\n",
        "                A_prime_idx = self.agent.action_idx(A)\n",
        "                \n",
        "                pair = (S, A)\n",
        "                E[pair] = E[pair] + 1 if pair in E.keys() else 1\n",
        "\n",
        "                delta = R + self.agent.gamma * Q[S_prime[0], S_prime[1], A_prime_idx] - Q[S[0], S[1], A_idx]\n",
        "\n",
        "                for (s, a) in E.keys():\n",
        "                    a_idx = self.agent.action_idx(a)\n",
        "                    Q[s[0],s[1], a_idx] += alpha * delta * E[(s,a)]\n",
        "                    E[(s,a)] *= self.agent.gamma * self.lam\n",
        "                \n",
        "                S = S_prime\n",
        "                A = A_prime\n",
        "                step_count += 1\n",
        "            self.episode_R.append(episode_R)\n",
        "            self.episode_length.append(step_count)\n",
        "            ec-=linear_decay\n",
        "            \n",
        "\n",
        "        self.agent.startPolicy(shape, random_policy)\n",
        "        self.agent.startV(shape)\n",
        "        for i in range(shape[0]):\n",
        "            for j in range(shape[1]):\n",
        "                if(self.environment.original_map[i][j] == '#'): self.agent.policy[i][j] = \"wall\"\n",
        "                else: \n",
        "                    self.agent.policy[i][j] = max(self.agent.actions, key = lambda action: Q[i,j, self.agent.action_idx(action)])\n",
        "                    self.agent.book_V[i][j] = max(Q[i,j,:])\n",
        "\n",
        "    def path_from(self, starting_point, Q):\n",
        "        shape = self.environment.get_size()\n",
        "        max_steps = shape[0] * shape[1]\n",
        "        step_count = 0\n",
        "        S = starting_point\n",
        "        self.environment.setAgentPos(S[0], S[1])\n",
        "        tuples = []\n",
        "        while (not self.environment.in_terminal_state()) and (step_count < max_steps):\n",
        "            A = self.get_greedy_action(S, Q)\n",
        "            R = self.environment.move(self.agent, A)\n",
        "            tuples.append((S,A,R))\n",
        "            S = (self.agent.y, self.agent.x)\n",
        "            step_count+=1\n",
        "        return tuples\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "class LinearFunctionApproximation(LearningStrategy):\n",
        "    ...\n",
        "\n",
        "class QLearning(LearningStrategy):\n",
        "    ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Environment:\n",
        "    default_symbols = {\"agent\": '@', \"wall\": '#', \"path\": '.', \"goal\":'$'}\n",
        "    def __init__(self, path, display=True, starting_point = (1,1)) -> None:\n",
        "        self.display = display\n",
        "        self.original_map = self.load_map(path)\n",
        "        self.map = self.copy_map(self.original_map)\n",
        "        self.wait_time = 0\n",
        "        self.starting_point = starting_point\n",
        "\n",
        "        if self.display:\n",
        "            self.render = Renderer(self, self.map, \"Ambiente\")\n",
        "            print(self.render)\n",
        "\n",
        "    def copy_map(self, map):\n",
        "        map_copy = []\n",
        "        for row in map:\n",
        "            map_copy.append([])\n",
        "            for cell in row:\n",
        "                map_copy[-1].append(cell)\n",
        "        return map_copy\n",
        "\n",
        "    def getAgent(self) -> Agent:\n",
        "        return self.agent\n",
        "\n",
        "    def in_terminal_state(self):\n",
        "        return self.original_map[self.agent.y][self.agent.x] == self.default_symbols[\"goal\"]\n",
        "\n",
        "\n",
        "    def load_map(self, path):\n",
        "        \"\"\"\n",
        "        Dado o caminho path, le um file txt e retorna uma matriz\n",
        "        O txt consiste de uma row contendo o numero n (nÃºmero de\n",
        "        rows do grid) e m (nÃºmero de caracteres diferentes no grid),\n",
        "        seguido de m rows explicando o que sao os caracteres no \n",
        "        file e por fim n rows contendo o grid que sao caracteres\n",
        "        \"\"\"\n",
        "\n",
        "        grid = []\n",
        "        self.symbols = dict()\n",
        "        self.rewards = {\"agent\": 0, \"wall\": 0, \"path\": 0, \"goal\":0}\n",
        "        with open(path, 'r') as file:\n",
        "            m, n = map(int, file.readline().split())\n",
        "            for _ in range(m):\n",
        "                row = file.readline().split()\n",
        "                self.symbols[row[0]] = row[1]\n",
        "                self.rewards[row[1]] = int(row[2])\n",
        "            for i in range(n):\n",
        "                row = file.readline()\n",
        "                grid.append([])\n",
        "                for j in range(len(row)):\n",
        "                    char = row[j]\n",
        "                    if char == '\\n':\n",
        "                        continue\n",
        "                    if self.symbols[char] == 'agent':\n",
        "                        self.agent = Agent(x=j, y=i, environment=self, display=self.display)\n",
        "                        char = self.default_symbols[\"path\"]\n",
        "                    grid[-1].append(self.default_symbols[self.symbols[char]])\n",
        "        return grid\n",
        "    \n",
        "    def move(self, agent, action):\n",
        "        \"\"\"\n",
        "        Dada uma action, move o agente no map\n",
        "        a action pode ser \"up\", \"down\", \"left\" ou \"right\"\n",
        "        \"\"\"\n",
        "        #time.sleep(self.wait_time)\n",
        "        direction = {\"up\": (-1, 0), \"down\": (1, 0), \"left\": (0, -1), \"right\": (0, 1)}\n",
        "        final_pos = (agent.y+direction[action][0], agent.x+direction[action][1])\n",
        "        if self.map[final_pos[0]][final_pos[1]] != self.default_symbols[\"wall\"]:\n",
        "            # seta a posicao atual como caminho\n",
        "            self.map[agent.y][agent.x] = self.original_map[agent.y][agent.x]\n",
        "            \n",
        "            # seta a posicao final como o agente\n",
        "            self.map[final_pos[0]][final_pos[1]] = self.default_symbols[\"agent\"]\n",
        "            \n",
        "            # atualiza a posicao do agente\n",
        "            agent.setPos(final_pos)\n",
        "        # retorna o reforco da posicao final \n",
        "        return self.rewards[self.symbols[self.original_map[agent.y][agent.x]]]\n",
        "\n",
        "    def util(self, pos, action):\n",
        "        \"\"\"\n",
        "        Dada uma posicao e uma action, retorna o que tem na posicao destino\n",
        "        \"\"\"\n",
        "        direction = {\"up\": (-1, 0), \"down\": (1, 0), \"left\": (0, -1), \"right\": (0, 1)}\n",
        "        final_pos = (pos[0]+direction[action][0], pos[1]+direction[action][1])\n",
        "        return self.symbols[self.map[final_pos[0]][final_pos[1]]] != \"wall\"\n",
        "\n",
        "    def get_size(self):\n",
        "        return len(self.map), len(self.map[0])\n",
        "    \n",
        "    def setAgentPos(self, i, j):\n",
        "        self.map[self.agent.y][self.agent.x] = self.original_map[self.agent.y][self.agent.x]\n",
        "        self.agent.setPos((i, j))\n",
        "        self.map[i][j] = self.default_symbols[\"agent\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<__main__.Renderer object at 0x0000028E91B69590>\n",
            "ep=0\n",
            "Tamanho do episÃ³dio: 400\n",
            "Recompensa -400\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ğŸ§±â¬†ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›âš½â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ep=5000\n",
            "Tamanho do episÃ³dio: 16\n",
            "Recompensa 85\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ğŸ§±â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¡ï¸ğŸ‘¾â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ep=10000\n",
            "Tamanho do episÃ³dio: 16\n",
            "Recompensa 85\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ğŸ§±â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¡ï¸ğŸ‘¾â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ep=15000\n",
            "Tamanho do episÃ³dio: 16\n",
            "Recompensa 85\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ğŸ§±â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¡ï¸ğŸ‘¾â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ep=20000\n",
            "Tamanho do episÃ³dio: 16\n",
            "Recompensa 85\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ğŸ§±â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¡ï¸ğŸ‘¾â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ep=25000\n",
            "Tamanho do episÃ³dio: 16\n",
            "Recompensa 85\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ğŸ§±â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¡ï¸ğŸ‘¾â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ep=30000\n",
            "Tamanho do episÃ³dio: 16\n",
            "Recompensa 85\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ğŸ§±â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¡ï¸ğŸ‘¾â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ep=35000\n",
            "Tamanho do episÃ³dio: 16\n",
            "Recompensa 85\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ğŸ§±â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¡ï¸ğŸ‘¾â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ep=40000\n",
            "Tamanho do episÃ³dio: 16\n",
            "Recompensa 85\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ğŸ§±â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¡ï¸ğŸ‘¾â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ep=45000\n",
            "Tamanho do episÃ³dio: 16\n",
            "Recompensa 85\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "ğŸ§±â¡ï¸â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¡ï¸â¡ï¸â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬‡ï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¡ï¸ğŸ‘¾â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›ğŸ§±\n",
            "ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±ğŸ§±\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "learning_strategy = MonteCarlo()\n",
        "environment = Environment('./salas/sala4.txt', True)\n",
        "agent = environment.getAgent()\n",
        "learning_strategy.setup(environment, agent)\n",
        "\n",
        "learning_strategy.train(50000, exploration_chance=0.3)\n",
        "print(\"Done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Renderer.create_heatmap(learning_strategy.agent.book_V, cmap='inferno', title='Sample Heatmap')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
